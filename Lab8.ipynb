{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-11T04:55:40.453072Z","iopub.execute_input":"2024-09-11T04:55:40.453909Z","iopub.status.idle":"2024-09-11T04:55:40.470810Z","shell.execute_reply.started":"2024-09-11T04:55:40.453811Z","shell.execute_reply":"2024-09-11T04:55:40.469492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2024-09-11T04:55:40.472685Z","iopub.execute_input":"2024-09-11T04:55:40.473069Z","iopub.status.idle":"2024-09-11T04:55:40.479457Z","shell.execute_reply.started":"2024-09-11T04:55:40.473025Z","shell.execute_reply":"2024-09-11T04:55:40.477633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\ndf = data[:100]\ndf","metadata":{"execution":{"iopub.status.busy":"2024-09-11T04:55:40.481349Z","iopub.execute_input":"2024-09-11T04:55:40.481818Z","iopub.status.idle":"2024-09-11T04:55:41.246247Z","shell.execute_reply.started":"2024-09-11T04:55:40.481769Z","shell.execute_reply":"2024-09-11T04:55:41.245068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1)  Preprocess (whatever yo think) <br>\n2)  Find out no. of words in corpus and total no.of unique vocab <br>\n3) Apply one hot encoding <br>\n4) apply bag of words and find the vocabulary also find the times each word has ocoured <br>\n5) Apply bag ow bigram, trigram, Write down observation about dimensionality of the vocabulary <br>\n6) Apply TF-IDF and find out IDF Scores of Woords, Also find out the Vocabulary","metadata":{}},{"cell_type":"code","source":"t = \"\"\nfor data in df['review']:\n    t = t +\"\"+ data\nprint(t)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T04:55:41.249015Z","iopub.execute_input":"2024-09-11T04:55:41.249404Z","iopub.status.idle":"2024-09-11T04:55:41.259059Z","shell.execute_reply.started":"2024-09-11T04:55:41.249366Z","shell.execute_reply":"2024-09-11T04:55:41.257769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords","metadata":{"execution":{"iopub.status.busy":"2024-09-11T04:55:41.260494Z","iopub.execute_input":"2024-09-11T04:55:41.260872Z","iopub.status.idle":"2024-09-11T04:55:41.268887Z","shell.execute_reply.started":"2024-09-11T04:55:41.260834Z","shell.execute_reply":"2024-09-11T04:55:41.267749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download('stopwords')\nsw = set(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2024-09-11T04:55:41.270450Z","iopub.execute_input":"2024-09-11T04:55:41.270793Z","iopub.status.idle":"2024-09-11T04:55:41.282164Z","shell.execute_reply.started":"2024-09-11T04:55:41.270755Z","shell.execute_reply":"2024-09-11T04:55:41.281033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"remove = [\"<\",\">\",\"br\",\"/\",\"?\",\"!\",\",\",\"''\",'\" \"',\"'\",'\"','[',']','(',')','{','}','\\\\','..','...','....','.','-','_',':',';','|','+','=','-','*','&','^','%','$','#','@','!','~','`']\nfor r in remove:\n    t = t.replace(r,'')\n\nt =  re.sub(r'\\d+', '', t)\nt","metadata":{"execution":{"iopub.status.busy":"2024-09-11T04:58:14.819386Z","iopub.execute_input":"2024-09-11T04:58:14.819811Z","iopub.status.idle":"2024-09-11T04:58:14.839754Z","shell.execute_reply.started":"2024-09-11T04:58:14.819763Z","shell.execute_reply":"2024-09-11T04:58:14.838433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize\n\ntext_wt = word_tokenize(t)\ntext_wt","metadata":{"execution":{"iopub.status.busy":"2024-09-11T04:55:41.310061Z","iopub.execute_input":"2024-09-11T04:55:41.310523Z","iopub.status.idle":"2024-09-11T04:55:41.412166Z","shell.execute_reply.started":"2024-09-11T04:55:41.310477Z","shell.execute_reply":"2024-09-11T04:55:41.411102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_sw = []\nfor word in text_wt:\n    word = word.lower()\n    if word not in sw:\n        text_sw.append(word)\n\ntext_sw","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-09-11T04:55:41.413712Z","iopub.execute_input":"2024-09-11T04:55:41.414098Z","iopub.status.idle":"2024-09-11T04:55:41.442188Z","shell.execute_reply.started":"2024-09-11T04:55:41.414060Z","shell.execute_reply":"2024-09-11T04:55:41.440862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len_Total_Words = len(text_sw)\nlen_Total_Words","metadata":{"execution":{"iopub.status.busy":"2024-09-11T04:55:41.443539Z","iopub.execute_input":"2024-09-11T04:55:41.443925Z","iopub.status.idle":"2024-09-11T04:55:41.453854Z","shell.execute_reply.started":"2024-09-11T04:55:41.443876Z","shell.execute_reply":"2024-09-11T04:55:41.452534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Unique_words = set(text_sw)\nTotal_Unique_words = len(Unique_words)\nprint(Total_Unique_words)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T05:03:36.418080Z","iopub.execute_input":"2024-09-11T05:03:36.418537Z","iopub.status.idle":"2024-09-11T05:03:36.425876Z","shell.execute_reply.started":"2024-09-11T05:03:36.418490Z","shell.execute_reply":"2024-09-11T05:03:36.424693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uniq_words = []\nuniq_words.extend(Unique_words)\nuniq_words","metadata":{"execution":{"iopub.status.busy":"2024-09-11T05:03:36.708281Z","iopub.execute_input":"2024-09-11T05:03:36.709304Z","iopub.status.idle":"2024-09-11T05:03:36.728594Z","shell.execute_reply.started":"2024-09-11T05:03:36.709257Z","shell.execute_reply":"2024-09-11T05:03:36.727465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Problem3: One Hot Encoding","metadata":{}},{"cell_type":"code","source":"arr = np.array(uniq_words).reshape(-1,1)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T05:03:38.204012Z","iopub.execute_input":"2024-09-11T05:03:38.204436Z","iopub.status.idle":"2024-09-11T05:03:38.212259Z","shell.execute_reply.started":"2024-09-11T05:03:38.204399Z","shell.execute_reply":"2024-09-11T05:03:38.210877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(arr,len(arr))","metadata":{"execution":{"iopub.status.busy":"2024-09-11T05:04:26.704929Z","iopub.execute_input":"2024-09-11T05:04:26.705332Z","iopub.status.idle":"2024-09-11T05:04:26.711247Z","shell.execute_reply.started":"2024-09-11T05:04:26.705297Z","shell.execute_reply":"2024-09-11T05:04:26.709915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder(sparse_output=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T05:03:48.061131Z","iopub.execute_input":"2024-09-11T05:03:48.061553Z","iopub.status.idle":"2024-09-11T05:03:48.067640Z","shell.execute_reply.started":"2024-09-11T05:03:48.061513Z","shell.execute_reply":"2024-09-11T05:03:48.066261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_ohe = ohe.fit_transform(arr)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T05:03:52.588412Z","iopub.execute_input":"2024-09-11T05:03:52.588839Z","iopub.status.idle":"2024-09-11T05:03:52.643170Z","shell.execute_reply.started":"2024-09-11T05:03:52.588798Z","shell.execute_reply":"2024-09-11T05:03:52.642075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_ohe","metadata":{"execution":{"iopub.status.busy":"2024-09-11T05:03:58.494118Z","iopub.execute_input":"2024-09-11T05:03:58.494518Z","iopub.status.idle":"2024-09-11T05:03:58.502496Z","shell.execute_reply.started":"2024-09-11T05:03:58.494482Z","shell.execute_reply":"2024-09-11T05:03:58.501397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-09-11T05:02:52.363944Z","iopub.execute_input":"2024-09-11T05:02:52.364374Z","iopub.status.idle":"2024-09-11T05:02:52.373177Z","shell.execute_reply.started":"2024-09-11T05:02:52.364336Z","shell.execute_reply":"2024-09-11T05:02:52.372054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Method2 for OHE","metadata":{}},{"cell_type":"code","source":"uniq_words_text = ' '.join(uniq_words)\nprint(uniq_words_text)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T05:33:34.077802Z","iopub.execute_input":"2024-09-11T05:33:34.078238Z","iopub.status.idle":"2024-09-11T05:33:34.085481Z","shell.execute_reply.started":"2024-09-11T05:33:34.078198Z","shell.execute_reply":"2024-09-11T05:33:34.084085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index = {\n}\nfor i, word in enumerate(uniq_words):\n    index[word] = i\nprint(index)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T05:33:34.646119Z","iopub.execute_input":"2024-09-11T05:33:34.646519Z","iopub.status.idle":"2024-09-11T05:33:34.657724Z","shell.execute_reply.started":"2024-09-11T05:33:34.646484Z","shell.execute_reply":"2024-09-11T05:33:34.656498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def one_hot_enc(text):\n    vec = []\n    for i in text.split():\n        v = np.zeros(len(uniq_words_text))\n        v[index[i.lower()]] = 1\n        vec.append(v)\n    return vec\n\ntext_ohe = one_hot_enc(uniq_words_text)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T05:33:34.924259Z","iopub.execute_input":"2024-09-11T05:33:34.924685Z","iopub.status.idle":"2024-09-11T05:33:35.523097Z","shell.execute_reply.started":"2024-09-11T05:33:34.924644Z","shell.execute_reply":"2024-09-11T05:33:35.521893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_ohe","metadata":{"execution":{"iopub.status.busy":"2024-09-11T05:33:35.524942Z","iopub.execute_input":"2024-09-11T05:33:35.525348Z","iopub.status.idle":"2024-09-11T05:33:35.668619Z","shell.execute_reply.started":"2024-09-11T05:33:35.525306Z","shell.execute_reply":"2024-09-11T05:33:35.667398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Problem 4: BoW and Frequence","metadata":{}},{"cell_type":"code","source":"uniq_words_text","metadata":{"execution":{"iopub.status.busy":"2024-09-11T05:33:36.598864Z","iopub.execute_input":"2024-09-11T05:33:36.599341Z","iopub.status.idle":"2024-09-11T05:33:36.608236Z","shell.execute_reply.started":"2024-09-11T05:33:36.599290Z","shell.execute_reply":"2024-09-11T05:33:36.606877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\n# documents = uniq_words_text.split()\nvectorizer = CountVectorizer()\n\nbow_matrix = vectorizer.fit_transform([uniq_words_text])\n\nbow_array = bow_matrix.toarray()\n\nfreq = vectorizer.get_feature_names_out()\n\n# Display the results\nprint(\"Vocabulary (Unique Wordss):\\n\", freq)\nprint(\"\\nBag of Words Matrix:\\n\", bow_array)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T05:33:37.132209Z","iopub.execute_input":"2024-09-11T05:33:37.132605Z","iopub.status.idle":"2024-09-11T05:33:37.161243Z","shell.execute_reply.started":"2024-09-11T05:33:37.132570Z","shell.execute_reply":"2024-09-11T05:33:37.159268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_freq_dict = dict(zip(freq, bow_array[0]))\nprint(\"Word Frequencies:\\n\", word_freq_dict)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T05:37:49.479400Z","iopub.execute_input":"2024-09-11T05:37:49.479905Z","iopub.status.idle":"2024-09-11T05:37:49.491261Z","shell.execute_reply.started":"2024-09-11T05:37:49.479854Z","shell.execute_reply":"2024-09-11T05:37:49.489756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}