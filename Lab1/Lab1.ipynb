{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3050fd-ce76-4676-9dca-477a7cd2c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize Words and Sentences\n",
    "# https://textanalysisonline.com/ --> Go through this website "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cf62c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "879f928a",
   "metadata": {},
   "source": [
    "## USING NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a9f84d1-2bd2-4a87-87ed-6bc808c8047e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/om-\n",
      "[nltk_data]     college/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02cf434d-2972-40f5-8b9b-6c32096e6524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fbd2cd82-d0f6-42ab-8850-c14f88aaefc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural Language Processing (NLP) is a subfield of computer science, artificial intelligence, information engineering, and human-computer interaction.',\n",
       " 'This field focuses on how to program computers to process and analyze large amounts of natural language data.',\n",
       " 'It is difficult to perform as the process of reading and understanding languages is far more complex than it seems at first glance.',\n",
       " 'Tokenization is a foundation step in NLP pipeline that shapes the entire workflow.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s = \"My name is Om M Patel. Currently in my 4th year of Undergrad. How are you ?\n",
    "s = \"Natural Language Processing (NLP) is a subfield of computer science, artificial intelligence, information engineering, and human-computer interaction. This field focuses on how to program computers to process and analyze large amounts of natural language data. It is difficult to perform as the process of reading and understanding languages is far more complex than it seems at first glance. Tokenization is a foundation step in NLP pipeline that shapes the entire workflow.\"\n",
    "sent_tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "788d882b-5fa0-4c28-a677-de70c83df88d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'subfield',\n",
       " 'of',\n",
       " 'computer',\n",
       " 'science',\n",
       " ',',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " ',',\n",
       " 'information',\n",
       " 'engineering',\n",
       " ',',\n",
       " 'and',\n",
       " 'human-computer',\n",
       " 'interaction',\n",
       " '.',\n",
       " 'This',\n",
       " 'field',\n",
       " 'focuses',\n",
       " 'on',\n",
       " 'how',\n",
       " 'to',\n",
       " 'program',\n",
       " 'computers',\n",
       " 'to',\n",
       " 'process',\n",
       " 'and',\n",
       " 'analyze',\n",
       " 'large',\n",
       " 'amounts',\n",
       " 'of',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'data',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'difficult',\n",
       " 'to',\n",
       " 'perform',\n",
       " 'as',\n",
       " 'the',\n",
       " 'process',\n",
       " 'of',\n",
       " 'reading',\n",
       " 'and',\n",
       " 'understanding',\n",
       " 'languages',\n",
       " 'is',\n",
       " 'far',\n",
       " 'more',\n",
       " 'complex',\n",
       " 'than',\n",
       " 'it',\n",
       " 'seems',\n",
       " 'at',\n",
       " 'first',\n",
       " 'glance',\n",
       " '.',\n",
       " 'Tokenization',\n",
       " 'is',\n",
       " 'a',\n",
       " 'foundation',\n",
       " 'step',\n",
       " 'in',\n",
       " 'NLP',\n",
       " 'pipeline',\n",
       " 'that',\n",
       " 'shapes',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'workflow',\n",
       " '.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = word_tokenize(s)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172c5827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c53c0b99",
   "metadata": {},
   "source": [
    "## Without Using NLTK (Python Logic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e44600f4-bda8-4969-af93-ea29f72c5cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(NLP)',\n",
       " 'is',\n",
       " 'a',\n",
       " 'subfield',\n",
       " 'of',\n",
       " 'computer',\n",
       " 'science,',\n",
       " 'artificial',\n",
       " 'intelligence,',\n",
       " 'information',\n",
       " 'engineering,',\n",
       " 'and',\n",
       " 'human-computer',\n",
       " 'interaction.',\n",
       " 'This',\n",
       " 'field',\n",
       " 'focuses',\n",
       " 'on',\n",
       " 'how',\n",
       " 'to',\n",
       " 'program',\n",
       " 'computers',\n",
       " 'to',\n",
       " 'process',\n",
       " 'and',\n",
       " 'analyze',\n",
       " 'large',\n",
       " 'amounts',\n",
       " 'of',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'data.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'difficult',\n",
       " 'to',\n",
       " 'perform',\n",
       " 'as',\n",
       " 'the',\n",
       " 'process',\n",
       " 'of',\n",
       " 'reading',\n",
       " 'and',\n",
       " 'understanding',\n",
       " 'languages',\n",
       " 'is',\n",
       " 'far',\n",
       " 'more',\n",
       " 'complex',\n",
       " 'than',\n",
       " 'it',\n",
       " 'seems',\n",
       " 'at',\n",
       " 'first',\n",
       " 'glance.',\n",
       " 'Tokenization',\n",
       " 'is',\n",
       " 'a',\n",
       " 'foundation',\n",
       " 'step',\n",
       " 'in',\n",
       " 'NLP',\n",
       " 'pipeline',\n",
       " 'that',\n",
       " 'shapes',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'workflow.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = s.split()\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c651c1bf-de32-4cb6-9d5f-99484a841054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural Language Processing (NLP) is a subfield of computer science, artificial intelligence, information engineering, and human-computer interaction',\n",
       " ' This field focuses on how to program computers to process and analyze large amounts of natural language data',\n",
       " ' It is difficult to perform as the process of reading and understanding languages is far more complex than it seems at first glance',\n",
       " ' Tokenization is a foundation step in NLP pipeline that shapes the entire workflow',\n",
       " '']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = s.split('.')\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05d7f395-c137-46b3-87c0-69c560e0b571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural Language Processing (NLP) is a subfield of computer science',\n",
       " ' artificial intelligence',\n",
       " ' information engineering',\n",
       " ' and human-computer interaction. This field focuses on how to program computers to process and analyze large amounts of natural language data. It is difficult to perform as the process of reading and understanding languages is far more complex than it seems at first glance. Tokenization is a foundation step in NLP pipeline that shapes the entire workflow.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l3 = s.split(',')\n",
    "l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "08af1307-c9e6-4c43-b189-2addf4c3b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try English Dictionary , (Scan words and if iy matches the dictionary then slice the word from their, before space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d223de2c-4b83-4a15-b6a7-ab34150b5ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('/Users/om-college/Library/CloudStorage/OneDrive-pdpu.ac.in/PDEU/NLP/words.txt', 'r') as file:\n",
    "    w = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c2505dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4862979\n"
     ]
    }
   ],
   "source": [
    "print(len(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce2b4979-e23d-4aea-999f-f73e9ab3b7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Processing', '(NLP)', 'is', 'a', 'subfield', 'of', 'computer', 'science,', 'artificial', 'intelligence,', 'information', 'engineering,', 'and', 'interaction.', 'This', 'field', 'focuses', 'on', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data.', 'It', 'is', 'difficult', 'to', 'perform', 'as', 'the', 'process', 'of', 'reading', 'and', 'understanding', 'languages', 'is', 'far', 'more', 'complex', 'than', 'it', 'seems', 'at', 'first', 'glance.', 'is', 'a', 'foundation', 'step', 'in', 'NLP', 'pipeline', 'that', 'shapes', 'the', 'entire']\n",
      "68 71\n"
     ]
    }
   ],
   "source": [
    "lists = []\n",
    "for i in l:\n",
    "    j = i.lower().replace('(','').replace(')','').replace('.','').replace(',','')\n",
    "    if j in w.lower():\n",
    "        lists.append(i)\n",
    "print(lists)\n",
    "print(len(lists),len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "173d90cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Processing', '(NLP)', 'is', 'a', 'subfield', 'of', 'computer', 'science,', 'artificial', 'intelligence,', 'information', 'engineering,', 'and', 'interaction.', 'This', 'field', 'focuses', 'on', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data.', 'It', 'is', 'difficult', 'to', 'perform', 'as', 'the', 'process', 'of', 'reading', 'and', 'understanding', 'languages', 'is', 'far', 'more', 'complex', 'than', 'it', 'seems', 'at', 'first', 'glance.', 'is', 'a', 'foundation', 'step', 'in', 'NLP', 'pipeline', 'that', 'shapes', 'the', 'entire']\n",
      "68 71\n"
     ]
    }
   ],
   "source": [
    "#optmised code for above\n",
    "import string\n",
    "\n",
    "change = str.maketrans('','', '().,')\n",
    "lists = [i for i in l if i.lower().translate(change) in w.lower()]\n",
    "print(lists)\n",
    "print(len(lists), len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "933a9853-b239-473a-b4c2-a88b5dfc2c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['human-computer', 'Tokenization', 'workflow.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst2 = [x for x in l if x not in lists]\n",
    "lst2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d63b16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aaad7383",
   "metadata": {},
   "source": [
    "## Using TextBLOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1cf9f76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3418.28s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: nltk>=3.8 in /Users/om-college/miniconda3/lib/python3.12/site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in /Users/om-college/miniconda3/lib/python3.12/site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/om-college/miniconda3/lib/python3.12/site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/om-college/miniconda3/lib/python3.12/site-packages (from nltk>=3.8->textblob) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in /Users/om-college/miniconda3/lib/python3.12/site-packages (from nltk>=3.8->textblob) (4.66.4)\n",
      "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.3/626.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: textblob\n",
      "Successfully installed textblob-0.18.0.post0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3426.25s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/om-\n",
      "[nltk_data]     college/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n",
      "[nltk_data] Downloading package punkt to /Users/om-\n",
      "[nltk_data]     college/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/om-\n",
      "[nltk_data]     college/nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/om-college/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package conll2000 to /Users/om-\n",
      "[nltk_data]     college/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data] Downloading package movie_reviews to /Users/om-\n",
      "[nltk_data]     college/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "! pip install -U textblob\n",
    "! python -m textblob.download_corpora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "73867cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob \n",
    "\n",
    "wiki = TextBlob(\"Python is a high-level, general-purpose programming language.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7b19e534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('high-level', 'JJ'),\n",
       " ('general-purpose', 'JJ'),\n",
       " ('programming', 'NN'),\n",
       " ('language', 'NN')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "wiki.tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dfac1bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['python'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fdc22c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.39166666666666666, subjectivity=0.4357142857142857)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testimonial = TextBlob(\"Textblob is amazingly simple to use. What great fun!\")\n",
    "testimonial.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cd49eb",
   "metadata": {},
   "source": [
    "## Using SPACY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a74759c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
